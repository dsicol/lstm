{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "42b77625",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4155a1f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import scipy\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sb\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr, norm\n",
    "import matplotlib.pyplot as plt \n",
    "sb.set() \n",
    "from math import sqrt\n",
    "from tensorflow import keras\n",
    "from statsmodels.tools import categorical\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from datetime import datetime, timedelta\n",
    "from keras.models import load_model\n",
    "from joblib import dump, load"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a914f13",
   "metadata": {},
   "source": [
    "# Select variable to predict \n",
    "`String prediction_variable`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181d98e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main variable = 'MainIncoming_kW'\n",
    "prediction_variable = 'MainIncoming_kW'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "46ac87e8",
   "metadata": {},
   "source": [
    "# Remove Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7e5ce0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Training_Data.csv')\n",
    "# remove units from length column and convert to float\n",
    "data['Timestamp'] = data['Timestamp'].str.replace(' Singapore', '').astype(str)\n",
    "data['MainIncoming_kW'] = data['MainIncoming_kW'].str.replace('kW', '').astype(float)\n",
    "data['CHWRT'] = data['CHWRT'].str.replace('°C', '').astype(float)\n",
    "data['CWRT'] = data['CWRT'].str.replace('°C', '').astype(float)\n",
    "data['CHWST'] = data['CHWST'].str.replace('°C', '').astype(float)\n",
    "data['CWST'] = data['CWST'].str.replace('°C', '').astype(float)\n",
    "data['CHW Flow'] = data['CHW Flow'].str.replace('L/s', '').astype(float)\n",
    "data['CDW Flow'] = data['CDW Flow'].str.replace('L/s', '').astype(float)\n",
    "data['heat_in'] = data['heat_in'].str.replace('_RT', '').astype(float)\n",
    "data['heat_out'] = data['heat_out'].str.replace('_RT', '').astype(float)\n",
    "data['lift'] = data['lift'].str.replace('Δ°C', '').astype(float)\n",
    "data['chwdt'] = data['chwdt'].str.replace('Δ°C', '').astype(float)\n",
    "data['cwdt'] = data['cwdt'].str.replace('Δ°C', '').astype(float)\n",
    "data['DemoSite Demo avgHum'] = data['DemoSite Demo avgHum'].str.replace('%RH', '').astype(float)\n",
    "data['DemoSite Demo avgTemp'] = data['DemoSite Demo avgTemp'].str.replace('°C', '').astype(float)\n",
    "data['DemoSite Demo Calculated Wet Bulb'] = data['DemoSite Demo Calculated Wet Bulb'].str.replace('°C', '').astype(float)\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52fdbe62",
   "metadata": {},
   "source": [
    "## Check data type (float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287da6d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(data.dtypes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fa6aa3f4",
   "metadata": {},
   "source": [
    "# Extract Individual Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae92d6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Timestamp'] =pd.to_datetime(data['Timestamp'], format=\"%Y-%m-%dT%H:%M:%S%z\")\n",
    "# convert the timestamp to the corresponding day of the week\n",
    "data['Day of Week'] = data['Timestamp'].dt.strftime('%A')\n",
    "# Convert datetime to weekday numbers (Monday=1, Tuesday=2, etc.)\n",
    "data['DayNumber'] = data['Timestamp'].dt.weekday\n",
    "# add 1 to get days starting from 1\n",
    "data['DayNumber'] = data['DayNumber'] + 1\n",
    "\n",
    "data['Year'] = data['Timestamp'].dt.year\n",
    "data['Month'] = data['Timestamp'].dt.month\n",
    "data['Day'] = data['Timestamp'].dt.day\n",
    "data['Hour'] = data['Timestamp'].dt.hour\n",
    "data['Minute'] = data['Timestamp'].dt.minute\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe3f413",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.drop(['Timestamp','Year','Month','Day','Day of Week'],axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ece169d",
   "metadata": {},
   "source": [
    "# Rearrange order of columns\n",
    "### Last column is the variable to be predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318332e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_column = data.columns.get_loc(prediction_variable) # 0-based\n",
    "if (prediction_variable == 'MainIncoming_kW'):\n",
    "    # Predicting for main variable; energy output\n",
    "    data = data.iloc[:, np.r_[prediction_column + 1:len(data.columns), prediction_column]]\n",
    "else:\n",
    "    # Predicting for chiller variable\n",
    "    data = data.iloc[:, np.r_[12:len(data.columns), prediction_column]]\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d633e888",
   "metadata": {},
   "source": [
    "# (Optional) Drop all weekend data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb9e74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekend_condition = data['DayNumber'] >= 6\n",
    "data_filtered = data.drop(data[weekend_condition].index)\n",
    "data_filtered"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d42aa0fe",
   "metadata": {},
   "source": [
    "# Preparing Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440922b4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Slice data into sequences\n",
    "seq_len = 24*3*4 #3days in 15min interval\n",
    "data_arr=[]\n",
    "for i in range(len(data)-seq_len+1):\n",
    "    data_slice = data[i:i+seq_len:]\n",
    "    data_arr.append(data_slice)\n",
    "data_arr = np.asarray(data_arr).astype('float32')\n",
    "print(len(data_arr))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba8f9bdf",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a64c127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train = data_arr[:11444]\n",
    "test_output = np.asarray(data)[11732:]\n",
    "train_x, train_y = train[:,:-1,:-1], train[:,-1,-1]\n",
    "test = data_arr[11732:]\n",
    "test_x, test_y = test[:,:-1,:-1], test[:,-1,-1]\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)\n",
    "# Construct the tensors, Reshape input to be 3D [samples, timesteps, features]\n",
    "train_x = train_x.reshape((train_x.shape[0], seq_len-1, train_x.shape[2]))\n",
    "test_x = test_x.reshape((test_x.shape[0], seq_len-1, test_x.shape[2]))\n",
    "print(train_x)\n",
    "print(test_x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d5f4058",
   "metadata": {},
   "source": [
    "# (Optional) Find Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74696a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initLSTMModel(neurons, dropout_rate, activation):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(seq_len, input_shape=(train_x.shape[1], train_x.shape[2])))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "    #model.add(Dense(1, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(\n",
    "        loss='mean_squared_error', \n",
    "        optimizer='adam', \n",
    "        metrics=[tf.keras.metrics.MeanSquaredError()]\n",
    "        )\n",
    "    return model\n",
    "\n",
    "# Set up parameter grid\n",
    "# Train with neurons, layers\n",
    "param_grid = {\n",
    "    'neurons': [24],\n",
    "\n",
    "}\n",
    "\n",
    "model = KerasRegressor(model=initLSTMModel, epochs=16, batch_size=32, neurons=24, dropout_rate=0.2, activation='relu')\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "# scoring='neg_mean_squared_error' as grid search will return maximum scoring\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error')\n",
    "grid_result = grid_search.fit(train_x, train_y)\n",
    "\n",
    "# Evaluate and extract the best model\n",
    "best_model = grid_result.best_estimator_\n",
    "test_accuracy = best_model.score(test_x, test_y)\n",
    "print(best_model)\n",
    "print(test_accuracy) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "505f8daa",
   "metadata": {},
   "source": [
    "# Create & Train Model \n",
    "### With best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a23df42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(LSTM(seq_len, input_shape=(train_x.shape[1], train_x.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(24, activation='relu'))\n",
    "model.add(Dense(24, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(\n",
    "    loss='mean_squared_error', \n",
    "    optimizer='adam', \n",
    "    metrics='[tf.keras.metrics.MeanSquaredError()]\n",
    "    )\n",
    "# Train the model\n",
    "history = model.fit(train_x, train_y, epochs=16, batch_size=32, validation_data=(test_x, test_y), verbose=True, shuffle=False)\n",
    "# Plot training history\n",
    "plt.plot(history.history['mean_absolute_error'], label='train')\n",
    "plt.plot(history.history['val_mean_absolute_error'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26c02da8",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cd8074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('ml2023_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe624ada",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#This part is for testing purpose not really needed\n",
    "past_10_day_test = pd.read_csv('Past_10_Days.csv')\n",
    "\n",
    "# remove units from length column and convert to float\n",
    "past_10_day_test['Timestamp'] = past_10_day_test['Timestamp'].str.replace(' Singapore', '').astype(str)\n",
    "past_10_day_test['MainIncoming_kW'] = past_10_day_test['MainIncoming_kW'].str.replace('kW', '').astype(float)\n",
    "past_10_day_test['CHWRT'] = past_10_day_test['CHWRT'].str.replace('°C', '').astype(float)\n",
    "past_10_day_test['CWRT'] = past_10_day_test['CWRT'].str.replace('°C', '').astype(float)\n",
    "past_10_day_test['CHWST'] = past_10_day_test['CHWST'].str.replace('°C', '').astype(float)\n",
    "past_10_day_test['CWST'] = past_10_day_test['CWST'].str.replace('°C', '').astype(float)\n",
    "past_10_day_test['CHW Flow'] = past_10_day_test['CHW Flow'].str.replace('L/s', '').astype(float)\n",
    "past_10_day_test['CDW Flow'] = past_10_day_test['CDW Flow'].str.replace('L/s', '').astype(float)\n",
    "past_10_day_test['heat_in'] = past_10_day_test['heat_in'].str.replace('_RT', '').astype(float)\n",
    "past_10_day_test['heat_out'] = past_10_day_test['heat_out'].str.replace('_RT', '').astype(float)\n",
    "past_10_day_test['lift'] = past_10_day_test['lift'].str.replace('Δ°C', '').astype(float)\n",
    "past_10_day_test['chwdt'] = past_10_day_test['chwdt'].str.replace('Δ°C', '').astype(float)\n",
    "past_10_day_test['cwdt'] = past_10_day_test['cwdt'].str.replace('Δ°C', '').astype(float)\n",
    "past_10_day_test['DemoSite Demo avgHum'] = past_10_day_test['DemoSite Demo avgHum'].str.replace('%RH', '').astype(float)\n",
    "past_10_day_test['DemoSite Demo avgTemp'] = past_10_day_test['DemoSite Demo avgTemp'].str.replace('°C', '').astype(float)\n",
    "past_10_day_test['DemoSite Demo Calculated Wet Bulb'] = past_10_day_test['DemoSite Demo Calculated Wet Bulb'].str.replace('°C', '').astype(float)\n",
    "\n",
    "actual_kW= past_10_day_test.loc[287:, ['MainIncoming_kW']]\n",
    "print(actual_kW)\n",
    "\n",
    "past_10_day_test['Timestamp'] =pd.to_datetime(past_10_day_test['Timestamp'],dayfirst=True)\n",
    "# convert the timestamp to the corresponding day of the week\n",
    "past_10_day_test['Day of Week'] = past_10_day_test['Timestamp'].dt.strftime('%A')\n",
    "# Convert datetime to weekday numbers (Monday=1, Tuesday=2, etc.)\n",
    "past_10_day_test['DayNumber'] = past_10_day_test['Timestamp'].dt.weekday\n",
    "# add 1 to get days starting from 1\n",
    "past_10_day_test['DayNumber'] = past_10_day_test['DayNumber'] + 1\n",
    "\n",
    "past_10_day_test['Year'] = past_10_day_test['Timestamp'].dt.year\n",
    "past_10_day_test['Month'] = past_10_day_test['Timestamp'].dt.month\n",
    "past_10_day_test['Day'] = past_10_day_test['Timestamp'].dt.day\n",
    "past_10_day_test['Hour'] = past_10_day_test['Timestamp'].dt.hour\n",
    "past_10_day_test['Minute'] = past_10_day_test['Timestamp'].dt.minute\n",
    "past_10_day_test.drop(['Timestamp','MainIncoming_kW','Year','Month','Day','Day of Week'],axis=1, inplace=True)\n",
    "testing = past_10_day_test\n",
    "\n",
    "data_arr1=[]\n",
    "for i in range(len(past_10_day_test)-seq_len+1):\n",
    "    data_slice = past_10_day_test[i:i+seq_len-1:]\n",
    "    data_arr1.append(data_slice)\n",
    "data_arr1 = np.asarray(data_arr1).astype('float32')\n",
    "past_10_day_test = data_arr1.reshape((data_arr1.shape[0], seq_len-1, data_arr1.shape[2]))\n",
    "test_Jan_Feb1 = model.predict(past_10_day_test)\n",
    "test_Jan_Feb1 = pd.DataFrame(test_Jan_Feb1, columns=['Predicted'])\n",
    "print(test_Jan_Feb1)\n",
    "\n",
    "test_Jan_Feb1.to_csv(\"check_test.csv\")\n",
    "actual_kW.to_csv(\"check_actual.csv\")\n",
    "# Make predictions on test data\n",
    "#test_pred = model.predict(test_x)\n",
    "\n",
    "# Calculate MAE and MSE for test and predicted values\n",
    "test_mae = mean_absolute_error(actual_kW, test_Jan_Feb1)\n",
    "test_mse = mean_squared_error(actual_kW, test_Jan_Feb1)\n",
    "\n",
    "print(\"Test MAE: \", test_mae)\n",
    "print(\"Test MSE: \", test_mse)\n",
    "\n",
    "# Define normalization function\n",
    "def normalize(values):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    normalized = scaler.fit_transform(values.reshape(-1, 1))\n",
    "    return normalized\n",
    "\n",
    "#change df to array\n",
    "test_Jan_Feb_final = test_Jan_Feb1.values\n",
    "actual_kW = actual_kW.values\n",
    "\n",
    "# Normalize test_y and predicted_y\n",
    "actual_kW_norm = normalize(actual_kW)\n",
    "predicted_kW_norm = normalize(test_Jan_Feb_final)\n",
    "\n",
    "# Calculate normalized MAE and MSE\n",
    "norm_mae = np.mean(np.abs(predicted_kW_norm - actual_kW_norm))\n",
    "norm_mse = np.mean(np.square(predicted_kW_norm - actual_kW_norm))\n",
    "\n",
    "print(\"Norm MAE: \", norm_mae)\n",
    "print(\"Norm MSE: \", norm_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d1e7da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
